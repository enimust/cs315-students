{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650e4d31-d281-4632-aa2b-a59b56fb541b",
   "metadata": {},
   "source": [
    "# Analyzing Trends on TikTok with Topic Modeling & Account Scraping\n",
    "\n",
    "This tutorial does the following:\n",
    "\n",
    "1. Connects to an existing (open) Chrome instance. **[Part 1](#sec1)**\n",
    "2. It shows how we can get information from a TikTok account page. **[Part 2](#sec2)**\n",
    "3. Shows how to use topic modeling analysis to underlying themes. **[Part 3](#sec3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5444f0-85f4-45d8-8e27-c961f2bfede2",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "## Part 1: Create Chrome Instance\n",
    "\n",
    "**Important:** For this to work, you should already have the Google instance running on your computer. To do that, open a console and run the command for your browser (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed7dab-5386-4226-9226-c3383b7f4ec9",
   "metadata": {},
   "source": [
    "**On Mac:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0bd9bd-6558-4826-8448-a2b4054be4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222 --user-data-dir=\"/tmp/chrome_dev_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6106590-83b7-450e-8ee1-8ee718bd11b6",
   "metadata": {},
   "source": [
    "**On Windows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba45b59-0663-40ca-b8c3-46658c01feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\" --remote-debugging-port=9222 --user-data-dir=\"C:\\selenium\\ChromeTestProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100c261-333b-4ba0-829f-b87523d90f89",
   "metadata": {},
   "source": [
    "**New installation**\n",
    "\n",
    "If you don't have the following package, install it once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0bd542-301a-439a-8779-a44210550a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a6da2-186e-441b-8239-ddae693bad01",
   "metadata": {},
   "source": [
    "Now you are ready to run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3005df9-2318-4408-8f42-53dcf7583ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# Set up Chrome options\n",
    "options = Options()\n",
    "options.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9222\")\n",
    "\n",
    "# Path to your ChromeDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "# Connect to the existing Chrome browser session\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789dc4d9-8a0f-4986-9e20-a985536d0271",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "## Part 2: Getting Information from a TikTok Page\n",
    "\n",
    "The following function scrapes a given account for its username, name, follower count, and total number of likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539068df-be50-442f-bf1f-b510e0fc9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccountInformation(driver):\n",
    "    \"\"\"\n",
    "    Given an open driver instance on a TikTok account page, \n",
    "    get the account metrics that are accessible.\n",
    "    \"\"\"\n",
    "    time.sleep(2) # in case the page hasn't loaded yet\n",
    "\n",
    "    account_info = {}\n",
    "\n",
    "    # Get the username \n",
    "    try:\n",
    "        account_info['author_username'] = driver.find_element(By.XPATH, '//*[@id=\"main-content-others_homepage\"]/div/div[1]/div[1]/div[2]/h1').text\n",
    "    except Exception as e:\n",
    "        print(f\"Username: An unexpected error occurred: {e}\")\n",
    "\n",
    "    # Get the name \n",
    "    try:\n",
    "        account_info['author_name'] = driver.find_element(By.XPATH, '//*[@id=\"main-content-others_homepage\"]/div/div[1]/div[1]/div[2]/h2').text\n",
    "    except Exception as e:\n",
    "        print(f\"Name: An unexpected error occurred: {e}\")\n",
    "\n",
    "    # Get the bio\n",
    "    try:\n",
    "        account_info['author_bio'] = driver.find_element(By.XPATH, '//*[@id=\"main-content-others_homepage\"]/div/div[1]/h2').text\n",
    "    except Exception as e:\n",
    "        print(f\"Likes: An unexpected error occurred: {e}\")\n",
    "\n",
    "    # Get the number of followers  \n",
    "    try:\n",
    "        account_info['author_followers'] = driver.find_element(By.XPATH, '//*[@id=\"main-content-others_homepage\"]/div/div[1]/h3/div[2]/strong').text\n",
    "    except Exception as e:\n",
    "        print(f\"Followers: An unexpected error occurred: {e}\")\n",
    "\n",
    "    # Get the number of likes \n",
    "    try:\n",
    "        account_info['author_likes'] = driver.find_element(By.XPATH, '//*[@id=\"main-content-others_homepage\"]/div/div[1]/h3/div[3]/strong').text\n",
    "    except Exception as e:\n",
    "        print(f\"Likes: An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "    return account_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81690946-0e36-4131-8ede-fd163fa7b13c",
   "metadata": {},
   "source": [
    "We can now run PykTok's \"author_username\" column through this function to get information about each account!\n",
    "\n",
    "This may take a while, depending on the size of your dataset. For this tutorial we are only taking a subset of the videos!\n",
    "\n",
    "**Note**: Make sure to add in your own csv pathname!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa734c60-2fb8-48c4-9bbd-9a87115a5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"\")\n",
    "\n",
    "df = df[['video_id', 'video_timestamp', 'video_duration',\n",
    "       'video_locationcreated', 'suggested_words', 'video_diggcount',\n",
    "       'video_sharecount', 'video_commentcount', 'video_playcount',\n",
    "       'video_description', 'hashtags', 'author_username']]\n",
    "\n",
    "# Get unique values from the \"account_username\" column and convert it to a list\n",
    "accounts = df['author_username'].unique().tolist()[::50]\n",
    "\n",
    "# Initialize an empty list to store account information dictionaries\n",
    "all_account_info = []\n",
    "\n",
    "for acc in accounts:\n",
    "    url = f\"https://tiktok.com/@{acc}\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Get account information\n",
    "    account_info = getAccountInformation(driver)\n",
    "\n",
    "    # Append the dictionary to the list\n",
    "    all_account_info.append(account_info)\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "data = pd.DataFrame(all_account_info)\n",
    "\n",
    "# Drop NaN rows\n",
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817eeee6-6640-48b8-9ae2-51d83f595c1c",
   "metadata": {},
   "source": [
    "We now have to merge this new dataframe onto our original PykTok dataset **accounts**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadba68-55f1-4fd4-bd6e-0f9771527aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "accountInformation = data.merge(df, on=\"author_username\", how=\"inner\").drop_duplicates()\n",
    "accountInformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30faa29-5b09-4480-a822-78997694bb1e",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>\n",
    "## Part 3: Topic Modeling for Descriptions of Videos\n",
    "\n",
    "We will now use the description and hashtags of the provided videos and the accounts' bios to see if there are any underlying themes! \n",
    "\n",
    "The following function, **lda_topic_modeling**, performs Latent Dirichlet Allocation (LDA) topic modeling on a dataset with textual data. Here's a breakdown of its functionality:\n",
    "\n",
    "- **data**: The dataset containing the textual data.\n",
    "- **column_names**: A list of column names from the dataset that contain text data. \n",
    "- **num_topics**: The number of topics to identify. The default is 5, but it can be adjusted to the desired level of granularity.\n",
    "\n",
    "**Combining Text Data:** The function first combines text from the specified columns into one by concatenating the text values row-wise. It handles missing values (NaNs) by filling them with empty strings.\n",
    "\n",
    "**Creating Document-Term Matrix (DTM):** It uses CountVectorizer from scikit-learn to convert the combined text data into a document-term matrix (DTM). The CountVectorizer converts a collection of text documents into a matrix of token counts.\n",
    "\n",
    "**Fitting LDA Model:** The function initializes and fits an LDA model using LatentDirichletAllocation from scikit-learn. LDA is a generative probabilistic model that discovers latent topics within a collection of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e561fe-8e99-40fb-bd70-d0b05452fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "def lda_topic_modeling(data, column_names, num_topics=5):\n",
    "    # Combine text from specified columns into one\n",
    "    data['combined_text'] = data[column_names[0]].fillna('') + ' ' + data[column_names[1]].fillna('') + ' ' + data[column_names[2]].fillna('') + data[column_names[3]].fillna('')\n",
    "    \n",
    "    # Create document-term matrix\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    dtm = count_vectorizer.fit_transform(data['combined_text'])\n",
    "    \n",
    "    # Fit LDA model\n",
    "    lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    lda_model.fit(dtm)\n",
    "    \n",
    "    # Display topics\n",
    "    feature_names = count_vectorizer.get_feature_names_out()\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        topics[f'Topic {topic_idx+1}'] = [feature_names[i] for i in topic.argsort()[:-11:-1]]\n",
    "    \n",
    "    return topics\n",
    "\n",
    "# Specify the columns containing text data\n",
    "columns = ['suggested_words', 'video_description', 'hashtags', 'author_bio']\n",
    "\n",
    "# Number of topics to identify\n",
    "num_topics = 10\n",
    "\n",
    "# Run LDA topic modeling\n",
    "topics = lda_topic_modeling(accountInformation, columns, num_topics)\n",
    "\n",
    "# Print the topics\n",
    "for topic, words in topics.items():\n",
    "    print(topic + \": \" + \", \".join(words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
